 <div><img src="https://capsule-render.vercel.app/api?type=waving&color=0:1FA9DC,100:D5E9AA&text=Earlips" /></div>


[![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2FGDSC-DGU%2F2024-SolutionChallenge-earlips-frontend&count_bg=%238B8B8B&title_bg=%231FA9DC&icon=wechat.svg&icon_color=%23E7E7E7&title=Connecting+your+ears+to+your+lips%2C+Earlips&edge_flat=false)](https://hits.seeyoufarm.com)

# üëã introduce team member

## [Back-End & AI](/2024-SolutionChallenge-earlips-AI/README.md)

| name                                        |major        |GDSC  | Email                |
| -------------------------------------------- | -------------- | ------ | -------------------- |
| [HUICHAN SEO](https://github.com/seochan99)       | Computer Science | LEAD | gmlcks0513@dgu.ac.kr |
| [HYEONJUNG HWANG](https://github.com/bunju20) | Computer Science     | General | ghkd4009@gmail.com |
| [SEONHO LEE](https://github.com/capableofanything)| Multi Media Engineering| Core |retsgo01@gmail.com|
| [EUNSEO LIM](https://github.com/som0309) |Imformation Comunication Engineering| General |eunseolim1018@naver.com|

</br>
</br>

# UN-SDGs that our solution is solving for
<p align="left">
  <img src="https://github.com/bunju20/2024-SolutionChallenge-earlips-frontend/assets/85238126/b2dff9f2-a73a-4757-820d-6db9eeb9d140" width="200" height="200"/>
  <img src="https://github.com/bunju20/2024-SolutionChallenge-earlips-frontend/assets/85238126/f8055493-2f91-407f-b3cd-dee878dd0d8f" width="200" height="200"/>
</p>

Our solution aims to provide hearing-impaired individuals with equal opportunities to express their thoughts freely through a pronunciation correction process. This process converts pronunciation into text for visual feedback, uses AI to detail areas needing improvement, and transforms the user's pronunciation into vibrations to provide tactile feedback. With our pronunciation correction process, we strive to eliminate the fear of speaking among the hearing-impaired and create a world where they can express their thoughts freely. 

Our approach aligns with promoting inclusive education (SDG 4) and reducing inequalities (SDG 10). We aim to contribute to a more inclusive and equitable world where everyone can freely express their thoughts, enjoy quality education, and experience reduced inequalities.



## Project Introduction
<img width="100%" alt="image" src="https://github.com/GDSC-DGU/2024-SolutionChallenge-earlips-frontend/assets/85238126/1db0ed9d-2afc-4f17-aa1e-51e0b03f278a">

## Architecture
<img width="100%" alt="image" src="https://github.com/GDSC-DGU/2024-SolutionChallenge-earlips-frontend/assets/85238126/20616201-352f-4983-8266-4f2298200275">



# ‚ú® Demo



##  ‚¨áÔ∏è Click For Watch the video!
[![Watch the video](https://img.youtube.com/vi/AKpShUiXPnk/maxresdefault.jpg)](https://youtu.be/AKpShUiXPnk)

## Our App APK 

[APK Download Link](https://drive.google.com/file/d/1ARsP2cMywcvQDSpFpK9n1j2Dt5KjHr6K/view?usp=sharing)


| Home Screen | Learning Screen | Phoneme Screen | Word Screen |
|-------------|-----------------|----------------|-------------|
| ![Home Screen](https://github.com/GDSC-DGU/2024-SolutionChallenge-earlips-frontend/assets/85238126/2cd6880c-c41e-40cf-9083-3123bbe650e6) | ![ÌïôÏäµÌéòÏù¥ÏßÄ](https://github.com/GDSC-DGU/2024-SolutionChallenge-earlips-frontend/assets/85238126/751e16d6-2652-4fad-94d7-96b732635370) | ![Î∞úÏùåÍ∏∞Ìò∏](https://github.com/GDSC-DGU/2024-SolutionChallenge-earlips-frontend/assets/85238126/bbd023dc-556c-4a8d-b965-ac1ce5c6e174) | ![Îã®Ïñ¥ÌïôÏäµÌïòÍ∏∞](https://github.com/GDSC-DGU/2024-SolutionChallenge-earlips-frontend/assets/85238126/a3c3a348-2b66-4927-abb0-06132f2a4015) |

**Home Screen** : Pronunciation score and daily learning graphs   
**Learning Screen**: Learning logs by date   
**Phoneme Screen** : Visuals and guides for phoneme articulation   
**Word Screen** : Features *sound-to-vibration buttons* , GIFs for pronunciation practice, interactive phoneme guides with Google's Gemini, detailed phoneme explanations, and *voice recording with result review*

| Sentance Screen(fix) | Paragraph Screen | Script Screen | live Screen(fix) |
|-------------|-----------------|----------------|-------------|
| ![·ÑÜ·ÖÆ·Ü´·Ñå·Ö°·Üº·Ñí·Ö°·Ü®·Ñâ·Ö≥·Ü∏](https://github.com/bunju20/2024-SolutionChallenge-earlips-frontend/assets/85238126/2c4b86d8-7e27-48d9-9f56-86e5c3e1ea51) |![·ÑÜ·ÖÆ·Ü´·ÑÉ·Ö°·Ü´·Ñí·Ö°·Ü®·Ñâ·Ö≥·Ü∏·Ñí·Ö°·ÑÄ·Öµ](https://github.com/bunju20/2024-SolutionChallenge-earlips-frontend/assets/85238126/9ddaf06b-a493-45d5-83f7-655770ab6db4) | ![·ÑÉ·Ö¢·Ñá·Ö©·Ü´·ÑÜ·Ö°·Ü´·ÑÉ·Ö≥·ÜØ·ÑÄ·Ö©·ÑÄ·Öß·ÜØ·ÑÄ·Ö™·ÑÄ·Ö°·Üπ](https://github.com/bunju20/2024-SolutionChallenge-earlips-frontend/assets/85238126/1b1d506e-4b53-4c53-bce9-1eaab7a5dc10) | ![·ÑÖ·Ö°·Ñã·Öµ·Ñá·Ö≥](https://github.com/bunju20/2024-SolutionChallenge-earlips-frontend/assets/85238126/d8b06861-7395-4c2d-8f7d-58fe6ccd8847) |

**Sentence Screen**: Same layout as the Word Screen.   
**Paragraph Screen**: Allows users to record their voice for a given script and receive feedback.   
**Script Screen**: Users can write their own scripts and record their voice for feedback.   
**Live Screen**: Displays the user's pronunciation in real time.   

---

# üõ†Ô∏è Tech

## Frameworks & Stack
![Numpy](https://img.shields.io/badge/Numpy-013243?style=for-the-badge&logo=numpy&logoColor=white)
![Librosa](https://img.shields.io/badge/Librosa-4B8BBE?style=for-the-badge&logo=librosa&logoColor=white)
![Jamo](https://img.shields.io/badge/Jamo-4B8BBE?style=for-the-badge&logo=jamo&logoColor=white)
![Torch](https://img.shields.io/badge/Torch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![Transformers](https://img.shields.io/badge/Transformers-29B6F6?style=for-the-badge&logo=transformers&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)
![Pydub](https://img.shields.io/badge/Pydub-FFA07A?style=for-the-badge&logo=python&logoColor=white)
![Python-Multipart](https://img.shields.io/badge/Python--Multipart-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Accelerate](https://img.shields.io/badge/Accelerate-2196F3?style=for-the-badge&logo=accelerate&logoColor=white)
![Uvicorn](https://img.shields.io/badge/Uvicorn-4B8BBE?style=for-the-badge&logo=uvicorn&logoColor=white)
![Hugging Face](https://img.shields.io/badge/Hugging%20Face-25B89B?style=for-the-badge&logo=huggingface&logoColor=white)
![OpenAI Whisper Large v3](https://img.shields.io/badge/OpenAI%2FWhisper%20Large%20v3-0082C8?style=for-the-badge&logo=openai&logoColor=white)

## Server
![Google Cloud Platform](https://img.shields.io/badge/Google%20Cloud%20Platform-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)
![Firebase](https://img.shields.io/badge/Firebase-FFCA28?style=for-the-badge&logo=firebase&logoColor=black)
---

## 1. Project Name
The name is earlips.

## 2. Introduce Project
The mission of the Solution Challenge is to solve for one or more of the United Nations' 17 Sustainable Development Goals using Google technology.
We provide pronunciation and speech learning services for individuals with hearing impairments.

## 3. Demonstration vedio and drive screens

### üíª Demonstration vedio
https://youtu.be/AKpShUiXPnk

## 4. Overall server structure
![image](https://github.com/GDSC-DGU/2024-SolutionChallenge-earlips-AI/assets/88440875/864bc8ec-3c14-45a1-b6db-d31ae0f42a51)

## 5. Running
### Setting Up a Virtual Machine Instance
* Create a Virtual Machine instance with one GPU T4 and 2 cores, equipped with 15GB of memory. In my case, I used Google Cloud Platform.
* Machine Type: n1-standard-4
* GPU: 1 x NVIDIA Tesla T4 
* Cores: 2
* Memory: 15GB
* Operating System: Deep Learning on Linux
* OS version: Deep Learning VM with CUDA 11.8 M116 : Debian 11, Python 3.10. With CUDA 11.8 preinstalled.
### Git File Upload Server
* Set up a git file upload server on the created Virtual Machine instance.
```console
# Example command for setting up git file upload server
git init --bare my-repo.git
```
### Installing Requirements
* In the server console, run the following command to install the necessary requirements:
```console
pip install -r requirements.txt
```
* In my case, I installed only "my_install_package.txt"
### Running the Server
* Make sure to replace x.x.x.x with the desired host IP address and x with the preferred port number.
* Execute the following command to run the server:
```console
uvicorn server:app --reload --host=x.x.x.x --port=x
```
* If you encounter an FFmpeg error, resolve it by running the following command in the server console:
```console
conda install ffmpeg
```
---
## 6. OpenSource 
* AI : openai/whisper-large-v3 (Hugging Face)
## 7. Generative AI
* AI : Gemini - We implemented a feature that uses Gemini to explain phonetic symbols in text
